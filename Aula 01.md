[[2024-09-24]]

**Cronograma de 10 módulos**
1. Introdução ao Aprendizado Profundo e NLP (Habernal) 
2. Representação de Texto e Modelos de Linguagem (Habernal) 
3. Modelos Seq2Seq de Classificação de Texto (CNN, RNNs) (Stanford + StatQuest)
4. Atenção em Modelos Seq2Seq e Processamento de sequências com entradas longas (StatQuest) 
5. Arquiteturas Transformer (StatQuest)
6. Pré-Treinamento e LLMs (Stanford)
7. Reinforcement Learning from Human Feddback (Stanford)
8. Modelos de Linguagem → Modelos de Mundo (Stanford)
Obs.: Ainda a ser atualizado

**Avaliação**
Duas provas: 20 pontos cada
Dois trabalhos práticos: 10 pontos cada 
Projeto de tema livre: 40 pontos

**Review do que será coberto nas próximas aulas**:
_ Basics 
- Residual Connections 
- Layer Normalization 
- Batch Normalization 
- Dropout 
- Sigmoid, ReLU, GELU, Softmax 
- MLPs, Convolutions

_ Losses
- Entropy 
- Cross Entropy 
- KL Divergence 
- l2 Regularization

 _ Optimizers
 - Stochastic Gradient Descent 
 - Adam 
 - AdamW 
 - Learning Rate Schedules

_ Datasets 
- Glue and Superglue 
- Squad 
- Librespeech 
- HuggingFace Datasets